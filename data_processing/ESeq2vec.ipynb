{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fair-esm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqJU4pkfXFVx",
        "outputId": "bde80445-5d06-4b8f-fb57-fb5653ff38e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
            "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOmUTBRFXwxR",
        "outputId": "6ea90611-b18a-445f-8734-327422ff8fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Biopython) (1.26.4)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Biopython\n",
            "Successfully installed Biopython-1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import time\n",
        "import torch\n",
        "import esm\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "import gc\n",
        "import argparse\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "Cx2ZpI3kd2r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/drive/MyDrive/CapstoneProject/ESM2/esm2_t6_8M_UR50D.pt https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\n",
        "!wget -O /content/drive/MyDrive/CapstoneProject/ESM2/esm2_t6_8M_UR50D-contact-regression.pt https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q2yxV0sp12EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.serialization.add_safe_globals([argparse.Namespace])\n",
        "FASTA_PATH = \"/content/drive/MyDrive/CapstoneProject/SeqRaw/UP000005640_9606.fasta\"\n",
        "#OUTPUT_PATH = \"/content/drive/MyDrive/CapstoneProject/Processed/seq_embeddings1.pkl\"\n",
        "#CHECKPOINT_PATH = OUTPUT_PATH + \".ckpt\"\n",
        "BATCH_SIZE = 1\n",
        "SAVE_INTERVAL = 50 #save checkpoint each 50 batches.\n",
        "# === 读取FASTA ===\n",
        "def read_fasta_file(fasta_path):\n",
        "    data = []\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        data.append((record.id, str(record.seq)))\n",
        "    return data\n",
        "\n",
        "print(\"Reading fasta...\")\n",
        "protein_data = read_fasta_file(FASTA_PATH)#20644 * 2 = m * n\n",
        "print(f\"Nums of Proteins: {len(protein_data)}\")\n",
        "\n",
        "processed_batches = 5000\n",
        "long_batch_index = [5265,5353]"
      ],
      "metadata": {
        "id": "MVTaJrQoiTh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 读取已处理的进度（如果有的话） ===\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/CapstoneProject/Processed/seq_embeddings4.pkl\"\n",
        "embeddings_dict = {}\n",
        "\"\"\"\n",
        "last_save_time = time.time()\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    with open(CHECKPOINT_PATH, \"rb\") as f:\n",
        "        checkpoint = pickle.load(f)\n",
        "        embeddings_dict = checkpoint[\"embeddings\"]\n",
        "        processed_batches = checkpoint[\"processed_batches\"]\n",
        "        last_save_time = checkpoint.get(\"last_save_time\", time.time())\n",
        "    print(f\"Resuming from batch {processed_batches + 1}\")\n",
        "\"\"\"\n",
        "# === 加载ESM-2模型（确保模型文件已下载）===\n",
        "print(\"Loading ESM-2 model...\")\n",
        "MODEL_PATH = \"/content/drive/MyDrive/CapstoneProject/ESM2/esm2_t33_650M_UR50D.pt\"\n",
        "REGRESSION_PATH = \"/content/drive/MyDrive/CapstoneProject/ESM2/esm2_t33_650M_UR50D-contact-regression.pt\"\n",
        "model, alphabet = esm.pretrained.load_model_and_alphabet_local(MODEL_PATH,)\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model.eval()\n",
        "print(\"Moedl Load Successed\")\n",
        "# === 设置 GPU 设备 ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用 GPU 或者 CPU\n",
        "model.to(device)  # 将模型移动到 GPU 或 CPU\n",
        "print(\"Model loaded successfully and moved to device:\", device)\n",
        "# === 开始处理（支持断点续跑）===\n",
        "total_batches = (len(protein_data) + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "#fp16\n",
        "#model = model\n",
        "\n",
        "#for i in range(processed_batches * BATCH_SIZE, len(protein_data), BATCH_SIZE):\n",
        "for i in range(processed_batches, len(protein_data)):\n",
        "    if i in long_batch_index:\n",
        "      print(f\"Skip long batch {i + 1}\")\n",
        "      processed_batches += 1\n",
        "      continue\n",
        "    batch = [(record[0], record[1]) for record in protein_data[i: i + BATCH_SIZE]]\n",
        "    print(batch)\n",
        "    batch_str_len = len(batch[0][1])\n",
        "    print(f\"current batch length = {batch_str_len}\")\n",
        "    if (batch_str_len > 6000):\n",
        "      print(\"Long batch Skip\")\n",
        "      long_batch_index.append(i)\n",
        "      continue\n",
        "    batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
        "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "    batch_tokens = batch_tokens.to(device)\n",
        "    # 计算嵌入\n",
        "    with torch.no_grad():\n",
        "        results = model(batch_tokens, repr_layers=[6])\n",
        "    token_representations = results[\"representations\"][6]\n",
        "    #print(f\"{batch_labels}, {batch_strs}, {batch_tokens}\")\n",
        "    print(f\"batche_len = {batch_lens} \")\n",
        "\n",
        "    #print(f\"token representation:\\n{token_representations}\")\n",
        "    for j, tokens_len in enumerate(batch_lens):\n",
        "        embedding = token_representations[j, 1:tokens_len-1].mean(0)\n",
        "        #output 1024 dim\n",
        "        pca = PCA(n_components=1024)\n",
        "        embeddings = pca.fit_transform(embeddings)\n",
        "        protein_id = batch_labels[j]\n",
        "        embeddings_dict[protein_id] = embedding.cpu().numpy()\n",
        "\n",
        "    # 更新已处理批次\n",
        "    processed_batches += 1\n",
        "    print(f\"Processed batch: {processed_batches}/{total_batches}\")\n",
        "    \"\"\"\n",
        "    # 每处理50 batches，自动保存进度\n",
        "    if processed_batches % SAVE_INTERVAL == 0:\n",
        "      checkpoint = {\n",
        "          \"embeddings\": embeddings_dict,\n",
        "          \"processed_batches\": processed_batches\n",
        "      }\n",
        "      with open(CHECKPOINT_PATH, \"wb\") as f:\n",
        "          pickle.dump(checkpoint, f)\n",
        "      print(f\"Saving CheckPoint at Batch {processed_batches}\")\n",
        "    \"\"\"\n",
        "    #gc to save grpah memory\n",
        "    del batch_tokens, token_representations,results\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \"\"\"\n",
        "    if processed_batches % 5000 == 0:\n",
        "      with open(OUTPUT_PATH, \"wb\") as f:\n",
        "        pickle.dump(embeddings_dict, f)\n",
        "      print(f\"Output 5000 batches which is {processed_batches} of total\")\n",
        "    \"\"\"\n",
        "with open(OUTPUT_PATH, \"wb\") as f:\n",
        "  pickle.dump(embeddings_dict, f)\n",
        "print(f\"long batch index is {long_batch_index}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === 训练完成，保存最终结果 ===\n",
        "\"\"\"\n",
        "with open(OUTPUT_PATH, \"wb\") as f:\n",
        "    pickle.dump(embeddings_dict, f)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "K59FVIZid3n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = protein_data[5000]\n",
        "len(batch[1])"
      ],
      "metadata": {
        "id": "xorKvz94sB1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "long batch index [5265, 5353, 6365, 11195, 11282, 12166, 12647, 13237, 13370, 16851, 19267, 20230]"
      ],
      "metadata": {
        "id": "hP8wDZ6p8sOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "SKKu2QeM5g70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "P9lrpEV9w487"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import esm\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "\n",
        "def read_fasta_file(fasta_path):\n",
        "    data = []\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        data.append((record.id, str(record.seq)))\n",
        "    return data\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"get Protein seq embeddings by esm-2\"\n",
        "    )\n",
        "    parser.add_argument(\"--fasta\", type=str, required=True,\n",
        "                        help=\"seq_file_path\")\n",
        "    parser.add_argument(\"--output\", type=str, required=True,\n",
        "                        help=\"output path\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
        "                        help=\"batch size, 32 default\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    #read fasta\n",
        "    print(\"reading fasta...\")\n",
        "    protein_data = read_fasta_file(args.fasta)\n",
        "    print(f\"Nums of Proteins：{len(protein_data)}\")\n",
        "\n",
        "    # load esm-2\n",
        "    print(\"load esm-2 650M Para version, Dim 1280 Embeddings...\")\n",
        "    model_path = \"/content/drive/MyDrive/CapstoneProject/ESM2/esm2_t33_650M_UR50D.pt\"\n",
        "    regression_path = \"/content/drive/MyDrive/CapstoneProject/ESM2/esm2_t33_650M_UR50D-contact-regression.pt\"\n",
        "    model, alphabet = esm.pretrained.load_model_and_alphabet_local(model_path, regression_path)\n",
        "    batch_converter = alphabet.get_batch_converter()\n",
        "    model.eval()\n",
        "\n",
        "    embeddings_dict = {}\n",
        "    batch_size = args.batch_size\n",
        "    total_batches = (len(protein_data) + batch_size - 1) // batch_size\n",
        "    for i in range(0, len(protein_data), batch_size):\n",
        "        batch = protein_data[i: i + batch_size]\n",
        "        batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
        "        # no padding tokens\n",
        "        batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            results = model(batch_tokens, repr_layers=[33])\n",
        "        # last layer reault as output\n",
        "        token_representations = results[\"representations\"][33]\n",
        "\n",
        "        # calcu means of the residues representations as global embeddings\n",
        "        for j, tokens_len in enumerate(batch_lens):\n",
        "            # token0 and the last token is the start and end signs respectively\n",
        "            embedding = token_representations[j, 1:tokens_len-1].mean(0)\n",
        "            protein_id = batch_labels[j]\n",
        "            embeddings_dict[protein_id] = embedding.cpu().numpy()\n",
        "\n",
        "        print(f\"proccessed batch:{i//batch_size + 1}/{total_batches}\")\n",
        "\n",
        "    # saving the embedding dict\n",
        "    output_path = Path(args.output)\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        pickle.dump(embeddings_dict, f)\n",
        "    print(f\"Save Successfully at：{output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sYYXcxumXR7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/CapstoneProject\")"
      ],
      "metadata": {
        "id": "mIUwG2d7nHat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl\n",
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7p624sw1UArM",
        "outputId": "6631e0a2-f95f-4a61-a7b6-766626613215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.14.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata>=0.5.0->dgl) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.32.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pglOUWn5VyAa",
        "outputId": "bf507714-ed7e-4443-9cbf-b36498443766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SWhMmiegV2E7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}